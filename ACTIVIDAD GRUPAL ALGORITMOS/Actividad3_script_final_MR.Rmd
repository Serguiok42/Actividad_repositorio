---
title: "Resolución Actividad 3 grupal máster Bioinformática UNIR (2024))"
author: "Sergio Benítez Fernández"
date: "2025-01-11"
output: html_document
---

```{r }
rm(list=ls())

path <- "C:/Users/Asus/OneDrive/bioinformatica/primer_quatri/algoritmos/actividad 3"
setwd (path)
#carga de las libreriaas utilizadas
library(MASS) # Libreria LDA
library(glmnet)
library(e1071)
library(readr)
library(caret)
library(klaR)
library(Metrics)

classes_df <- read_delim("classes.csv", col_names = c("Sample", "Class"), delim = ";", show_col_types = FALSE)

# Leer el archivo de nombres de columnas
column_names <- readLines("column_names.txt")
column_names

# Leer el archivo expression_values.csv
expression_genes <- read_delim("gene_expression.csv", delim = ";", show_col_types = FALSE)


# Asignar los nombres de las columnas del archivo column_names.txt al dataframe de valores de expresión
colnames(expression_genes) <- column_names

#Comprobación de columnas vacías
sumas <- colSums(expression_genes) # sumo los datos por columnas
columnascero <- names(sumas[sumas==0]) # veo cuantas sumas son == 0
print(columnascero) # veo qué columnas están vacías
Expresión_de_genes_df_final <- expression_genes[, !names(expression_genes) %in% columnascero] # reemplazo el dataset df sin esas columnas
Expresión_de_genes_df_final <- scale(Expresión_de_genes_df_final) #normalización de los datos (z-score)



# Existe discrepancia en el número muestral entre los dataframes classes_df y expression_genes

# Eliminar la fila sample_0 en classes_df 
classes_df_depurada <- classes_df[classes_df$Sample != "sample_0", ]

# Combinar los dataframes

combined_df <- cbind(classes_df_depurada, Expresión_de_genes_df_final)


# Verificar el contenido del dataframe combinado
head(combined_df)

combined_df[] <- lapply(combined_df, function(x) {
  if (is.numeric(x)) {
    x[is.na(x)] <- median(x, na.rm = TRUE)
  }
  return(x)
})
# Verificar si los NA han sido imputados
sum(is.na(combined_df)) 




```
##  Métodos no supervisados
```{r}
## MÉTODOS NO SUPERVISADOS ######

       ### REDUCCIÓN DE LA DIMENSIONALIDAD #####

############## Algoritmo ISOMAP #############

install.packages("RDRToolbox", repos = "http://cran.us.r-project.org")
library(RDRToolbox)
# Guardar las clases en un vector separado antes de convertir a matriz
clases <- combined_df$Class

# Excluir las columnas 'Sample' y 'Class' para preparar la matriz de datos
combined_df_matrix <- as.matrix(combined_df[, -c(1, 2)])

# Calcular el análisis Isomap
isomap.results <- Isomap(data = combined_df_matrix, dims = 1:4, k =15, plotResiduals=TRUE)

# Crear dataframe para la visualización (usando las primeras dos dimensiones)
isomap.df <- data.frame(isomap.results$dim2)

# Añadir la columna de clases para usarla en la visualización
isomap.df$clases <- clases

# Graficar los resultados de Isomap
ggplot(isomap.df, aes(x = X1, y = X2, color = clases)) +
  geom_point(size = 3) +
  scale_color_manual(values = c("red", "blue", "green", "orange", "purple")) +
  labs(title = "Isomap", 
       x = 'dim1', 
       y = 'dim2', 
       color = "TIPO") +
  theme_classic() +
  theme(panel.grid.major = element_line(color = "gray90"),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "gray95"),
        plot.title = element_text(hjust = 0.5))




############## Algoritmo tSNE #############
library(Rtsne)
# Seteamos la semilla para que sea replicable el algoritmo
set.seed(1234)


# Guardado en un dataframe de los 500 primeros genes 
data3 <- sapply(combined_df[3:499], as.numeric)

# Algoritmo
# funcion Rtsne()
#   X: datos sobre los que reduciremos la dimensionalidad
#   dims: tamaño final del conjunto de datos (mejor <=3) por eficiencia
#   num_threads: hilos a utilizar (procesadores). No hace falta usarlo de momento
# 
#   Variable Y con matriz del t-SNE

tsne <- Rtsne(X=data3)
tsne_result <- data.frame(tsne$Y)

# Graficamos
ggplot(tsne_result, aes(x = X1, y = X2, color = classes_df_depurada$Class)) +
  geom_point(size = 3) +
  scale_color_manual(values = c("red", "blue", "green", "orange", "purple")) +
  labs(title = "Método t-SNE", x = "PC1", y = "PC2", color = "TIPO") +
  theme_classic() +
  theme(panel.grid.major = element_line(color = "gray90"), panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "gray95"), plot.title=element_text(hjust=0.5))



         ### CLUSTERING #####

############## Algoritmo WARD #############

#### ---- Clustering jerarquico aglomerativo (de abajo a arriba): datos con poca cantidad de observaciones ----
library(ggdendro)
library(cluster)
library(factoextra)
library(gridExtra)


# Calcular la matriz de distancia
dist_matrix <- dist(combined_df)

# Se ejecuta el algoritmo de clusterización jerárquica aglomerativa

hclust_model_ward <- hclust(dist_matrix, method = "ward.D") # agrupa los clusters tratando de que sean lo más COMPACTOS posible minimizando la dispersión interna

colors <- rainbow(5)
k= 5
# Ward: crea clusters redondeados y homogéneos similares a los que genera k-means, PERO no funciona tan bien si los clusters tienen formas raras o tamaños muy diferentes
clust_ward <- fviz_dend(hclust_model_ward, 
                        cex = 0.5,
                        k = k,
                        palette = colors,
                        main = "Ward",
                        xlab = "Índice de Observaciones",
                        ylab = "Distancia",
                        label_row = TRUE) + 
  theme_classic()

grid.arrange(clust_ward, nrow = 2)
# ward.D: datos en los que esperas clusters compactos y homogéneos -> "Los datos deberían agruparse en clusters compactos con baja variabilidad interna."

expression_genes$cluster_ward <- as.factor(cutree(hclust_model_ward, k = 5))  #este código nos permite ver los subgrupos (númerados del 1 al 5) en el dataframe original, que no estaba etiquetado y , por tanto, poder estudiar y comparar las caracteristicas de la muestra de cada cluster en el dataframe)


          ##### algoritmo K-MEANS ######

# Calcular el parametro k, para estimar cuantos clusteres es más óptimo en este caso
fviz_nbclust(isomap.df[, 1:2], kmeans, method = "wss") +  # Usamos Isomap para el análisis del codo
  ggtitle("Optimal number of clusters", subtitle = "") +
  theme(panel.grid.major = element_line(color = "gray90"),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "gray95"),
        plot.title = element_text(hjust = 0.5, margin = margin(b = -10)))

# En este caso se fija k = 5

#Calculamos k-means
kmeans.result <- kmeans(isomap.df[, 1:2], centers = 5, iter.max = 100, nstart = 25)  # Realiza K-means con las dos primeras dimensiones de Isomap

# Visualizar los clusters obtenidos por K-means
fviz_cluster(kmeans.result, data = isomap.df[, 1:2], xlab = '', ylab = '') +
  ggtitle("Cluster plot, k = 5", subtitle = "") +
  theme(plot.title = element_text(hjust = 0.5, margin = margin(b = -10)))
```

##reduccion de dimensionalidad

```{r lasso, warning = FALSE, results='hide'}
# Removemos la columna Sample y convertimos Class a factor
combined_df$Class <- as.factor(combined_df$Class)
x <- as.matrix(combined_df[, !names(combined_df) %in% c("Sample", "Class")])
y <- combined_df$Class

# Aseguramos que x sea numérica
x <- apply(x, 2, as.numeric)

# Seleccionamos características usando Lasso
set.seed(123)
cv_lasso <- cv.glmnet(x, y, alpha = 1, family = "multinomial")
best_lambda <- cv_lasso$lambda.min
lasso_model <- glmnet(x, y, alpha = 1, lambda = best_lambda, family = "multinomial")

# Obtener coeficientes para todas las clases
coef_list <- coef(lasso_model)

# Combinamos los coeficientes de todas las clases
all_coefs <- do.call(cbind, lapply(coef_list, as.matrix))

# Encontramos características con coeficientes no nulos en cualquier clase
selected_features <- which(rowSums(abs(all_coefs[-1,])) != 0)

# Creamos nuevo conjunto de datos con las características seleccionadas
data_selected <- combined_df[, c("Class", names(combined_df)[selected_features])]

```


## Metodos supervisados

```{r división de la base de datos, error=TRUE, warning=FALSE, message=FALSE}
# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba
set.seed (123) #Determinamos la semilla de aleatoriedad
trainIndex <- createDataPartition(data_selected$Class, p = 0.8, list = FALSE) #Division de los datos 80% para entrenar, 20% para test)

train_data <- data_selected[trainIndex,] #Datos para entrenar el modelo
test_data <- data_selected[-trainIndex,] #Datos para testearlo (los contrarios al de entreno)

table(train_data$Class) #Tabla con el numero de muestras para cada tipo de clase para los datos de entreno
table(test_data$Class)#Tabla con el numero de muestras para cada tipo de clase para los datos de test 

numerical_columns <- train_data[, sapply(train_data, is.numeric)] #Seleccionamos todos los datos numericos
scaled_data <- scale(numerical_columns) #Escalado de los datos seleccionados
scaled_data <- as.data.frame(scaled_data)
training_data <-  cbind(scaled_data, Class = train_data$Class) #Creacion de tabla con los datos escalados + columna de diagnosis

numerical_columns <- test_data[, sapply(test_data, is.numeric)] #Seleccionamos todos los datos numericos
scaled_data <- scale(numerical_columns) #Escalado de los datos seleccionados
scaled_data <- scale(numerical_columns) #Escalado de los datos seleccionados
scaled_data <- as.data.frame(scaled_data)
testing_data <- cbind(scaled_data, Class = test_data$Class) #Creacion de tabla con los datos escalados + columna de diagnosis


training_data <- as.data.frame(training_data)
testing_data <- as.data.frame(testing_data)

training_data$Class <- as.factor (train_data$Class)
testing_data$Class <- as.factor (test_data$Class)

# Crear la formula sumando cada gen
length(training_data) #Para saber cuantas variables se encuentran
names <- colnames(training_data[1:100]) #La variable clases no se incluye
formula <- as.formula(paste("Class ~", paste(names, collapse = "+"))) #Se obtiene la formula del diagnosis junto a la suma de todos los parametros
formula

```


## SVM lineal

```{r SVM lineal, error=TRUE, warning=FALSE, message=FALSE, echo = TRUE}
#SVM lineal
svmModelLineal <- train(Class ~.,
                        data = training_data,
                        method = "svmLinear",
                        trControl = trainControl(method = "cv", number = 10),
                        preProcess = c("center", "scale"),
                        tuneGrid = expand.grid(C = seq(0, 2, length = 20)), 
                        prob.model = TRUE) 


# Obtenemos las predicciones de las clases
predicciones_SVM <- predict(svmModelLineal, test_data)

#Creo la matriz de confusión para comparar los datos predichos con los reales.
confusion_matrix_SVM <- confusionMatrix(predicciones_SVM, testing_data$Class)

#obtengo matriz de confusión,y saco datos como la precisión, sensibilidad, especificidad y score-F1 para las distintas clases 
confusion_matrix_SVM
```


```{r SVM lineal, error=TRUE, warning=FALSE, message=FALSE}
precision_SVM <- confusion_matrix_SVM$overall['Accuracy']
precision_SVM

sensitivity_SVM <- as.numeric(confusion_matrix_SVM$byClass[, "Sensitivity"])
sensitivity_SVM

specificity_SVM <- as.numeric(confusion_matrix_SVM$byClass[, "Specificity"])
specificity_SVM

f1_score_SVM <- as.numeric(confusion_matrix_SVM$byClass[,'F1'])
f1_score_SVM

```
## LDA

```{r LDA, warning = FALSE,echo = FALSE}
# Ajuste del modelo LDA en el entrenamiento
lda_model <- lda(formula, data = training_data) 
lda_model$scaling # contribuciones/coeficientes


lda_pred <- predict(lda_model, newdata = training_data)
lda_pred$x

# Realizar predicciones sobre el conjunto de prueba
lda_predictions <- predict(lda_model, newdata = testing_data)
lda_predictions$x

# Obtener la predicción (predicciones de la clase)
predicted_classes <- lda_predictions$class
predicted_classes

#Comprobacion de que se ha obtenido el mismo numero de predicciones que de los datos de testing
length(predicted_classes) 
length (testing_data$Class)

# Obtener las verdaderas etiquetas (las clases reales en el conjunto de prueba)
true_classes <- as.factor(testing_data$Class)
true_classes
length(true_classes)
```


```{r matrix LDA, warning = FALSE,echo = TRUE}
# Crear la matriz de confusion 
confusion_matrix_LDA <- confusionMatrix(predicted_classes, true_classes)

#Imprimir la matriz de confusion
print(confusion_matrix_LDA)
```


```{r matrix LDA, warning = FALSE,echo = TRUE}
#Muestra el numero de Precision 
precision_LDA <- confusion_matrix_LDA$overall['Accuracy']
precision_LDA

#Muestra el numero de Sensibilidad
sensitivity_LDA <- as.numeric(confusion_matrix_LDA$byClass[, "Sensitivity"])
sensitivity_LDA

#Muestra el numero de Especificidad
specificity_LDA <- as.numeric(confusion_matrix_LDA$byClass[, "Specificity"])
specificity_LDA

#Muestra el F1-Score
f1_score_LDA <- as.numeric(confusion_matrix_LDA$byClass[,'F1'])
f1_score_LDA

```



## RDA (Regularized Discriminant Analysis)

Ajuste del modelo RDA al entrenamiento y carga de paquetes para el RDA

```{r RDA preprocesamiento, echo = FALSE}
library(klaR)
library(Metrics)

rda_model <- rda(formula, data = training_data)
rda_model
rda_pred <- predict(rda_model, newdata = training_data)
(rda_pred)
summary(cars)

#Realizar predicciones sobre el conjunto de prueba
rda_predictions <- predict(rda_model, newdata = testing_data)
(rda_predictions)

#Obtener la predicción (predicciones de la clase)
predicted_classes <- rda_predictions$class
predicted_classes

#Comprobacion de que se ha obtenido el mismo numero de predicciones que de los datos de testing
length(predicted_classes) 
length (testing_data$Class)

#Obtener las verdaderas etiquetas (las clases reales en el conjunto de prueba)
true_classes <- as.factor(testing_data$Class)
true_classes
length(true_classes)
```


```{r matrix RDA, echo = TRUE}
# Crear la matriz de confusion 
confusion_matrix_RDA <- confusionMatrix(predicted_classes, true_classes)

#Imprimir la matriz de confusion
print(confusion_matrix_RDA)
```


```{r F1 Score RDA, echo = TRUE}
#Muestra el F1-Score
f1_score_RDA <- as.numeric(confusion_matrix_RDA$byClass[,'F1'])
f1_score_RDA
```


```{r matrix RDA, echo = FALSE}
#Crear la matriz de confusión como un dataframe para visualizar en R
confusion_matrix_RDA <- as.data.frame(as.table(confusion_matrix_RDA))
```
